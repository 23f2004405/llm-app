# app.py - LLM Code Deployment System
from fastapi import FastAPI, Request
import os
import base64
import requests
import json
import re
import time
import logging
from typing import Dict, Any, Optional, List

# --- Configuration ---
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
AIPIPE_TOKEN = os.getenv("AI_PIPE_TOKEN")
GITHUB_USER = "23f2004405"
SECRET = os.getenv("SECRET")

app = FastAPI()

# --- Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Security ---
SECRET_PATTERNS = [
    re.compile(r"AKIA[0-9A-Z]{16}"),
    re.compile(r"(?:api|token|secret|key)[=:]\s*['\"]?[0-9a-zA-Z-_]{20,}"),
    re.compile(r"[0-9a-fA-F]{32,}"),
    re.compile(r"[A-Za-z0-9+/]{40,}={0,2}")
]

def validate_secret(secret: str) -> bool:
    return secret == SECRET

def github_headers():
    return {
        "Authorization": f"Bearer {GITHUB_TOKEN}",
        "Accept": "application/vnd.github+json"
    }

# --- GitHub Operations ---
def create_github_repo(repo_name: str) -> Dict[str, Any]:
    url = "https://api.github.com/user/repos"
    headers = github_headers()
    payload = {
        "name": repo_name,
        "private": False,
        "auto_init": True,
        "license_template": "mit",
        "description": "Auto-generated by LLM Code Deployment system"
    }
    r = requests.post(url, headers=headers, json=payload)
    if r.status_code == 201:
        return r.json()
    if r.status_code == 422 and "already exists" in r.text:
        return {"name": repo_name}
    raise Exception(f"Failed to create repo: {r.text}")

def push_file_to_repo(repo_name: str, file_path: str, content_bytes: bytes, message="Add file") -> Dict[str, Any]:
    url = f"https://api.github.com/repos/{GITHUB_USER}/{repo_name}/contents/{file_path}"
    headers = github_headers()
    r = requests.get(url, headers=headers)
    sha = r.json().get("sha") if r.status_code == 200 else None

    b64 = base64.b64encode(content_bytes).decode()
    data = {"message": message, "content": b64}
    if sha:
        data["sha"] = sha

    r = requests.put(url, headers=headers, json=data)
    if r.status_code not in (200, 201):
        raise Exception(f"Failed to push {file_path}: {r.text}")
    return r.json()

def contains_secret(content_bytes: bytes) -> bool:
    text = content_bytes.decode(errors="ignore")
    return any(pattern.search(text) for pattern in SECRET_PATTERNS)

def push_file_safe(repo_name: str, file_path: str, content_bytes: bytes, message="Add file") -> Dict[str, Any]:
    if contains_secret(content_bytes):
        logger.warning(f"Skipped {file_path} - secrets detected")
        return {"skipped": True}
    return push_file_to_repo(repo_name, file_path, content_bytes, message)

def enable_github_pages(repo_name: str):
    headers = github_headers()
    url = f"https://api.github.com/repos/{GITHUB_USER}/{repo_name}/pages"
    payload = {"source": {"branch": "main", "path": "/"}}
    r = requests.post(url, headers=headers, json=payload)
    if r.status_code in (200, 201):
        return True
    elif r.status_code == 422:
        r = requests.put(url, headers=headers, json=payload)
        return r.status_code in (200, 201, 204)
    return False

# --- Data URI & Attachments ---
DATA_URI_RE = re.compile(r"data:(?P<mime>[^;]+)(;base64)?,(?P<data>.*)")

def decode_data_uri(uri: str) -> bytes:
    m = DATA_URI_RE.match(uri)
    if not m:
        raise ValueError("Invalid data URI")
    data_str = m.group("data")
    if ";base64" in uri:
        # Add missing padding if needed
        data_str += "=" * ((4 - len(data_str) % 4) % 4)
        return base64.b64decode(data_str)
    return data_str.encode()


def process_attachments(attachments: List[dict]) -> Dict[str, bytes]:
    files = {}
    for att in attachments:
        try:
            files[att["name"]] = decode_data_uri(att["url"])
        except Exception as e:
            logger.error(f"Failed to process {att['name']}: {e}")
    return files

# --- File Generation ---
def generate_mit_license() -> str:
    return """MIT License

Copyright (c) 2024

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE."""

def generate_readme(repo_name: str, brief: str, checks: List[str]) -> str:
    return f"""# {repo_name}

## Overview
{brief}

## Setup
Open `index.html` in a browser or visit the GitHub Pages URL.

## Features
- Single-page web application
- Self-contained HTML/CSS/JS
- Mobile-responsive

## Evaluation Criteria
{chr(10).join(f"- {check}" for check in checks)}

## License
MIT License

## Live Demo
https://{GITHUB_USER}.github.io/{repo_name}/
"""

# --- AI Pipe Integration ---
def ask_aipipe_for_files(brief: str, attachments: List[dict] = None) -> Dict[str, bytes]:
    url = "https://aipipe.org/openai/v1/responses"
    headers = {"Authorization": f"Bearer {AIPIPE_TOKEN}", "Content-Type": "application/json"}

    attachment_context = ""
    if attachments:
        attachment_context = "\n\nAvailable files:\n" + "\n".join([f"- {att['name']}" for att in attachments])

    system_prompt = (
        "Generate ONE single-page web app (index.html) that works on GitHub Pages. "
        "Include all CSS/JS in one file. Make it responsive and user-friendly. "
        "Output ONLY JSON: {'index.html': '<html>...</html>'}"
    )
    user_prompt = f"Create a web app that: {brief}{attachment_context}"

    payload = {
        "model": "gpt-4.1-nano",
        "input": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    }

    r = requests.post(url, headers=headers, json=payload, timeout=60)
    if r.status_code != 200:
        raise Exception(f"AI call failed: {r.text}")

    resp = r.json()
    text = ""
    if "output" in resp and isinstance(resp["output"], list) and resp["output"]:
        content = resp["output"][0].get("content", [])
        text = "".join([c.get("text","") if isinstance(c, dict) else str(c) for c in content])

    try:
        files_obj = json.loads(text)
    except:
        m = re.search(r"(\{.*\})", text, flags=re.S)
        files_obj = json.loads(m.group(1)) if m else {}

    return {fname: content.encode("utf-8") for fname, content in files_obj.items()}

# --- Evaluation ---
def post_to_evaluation_url(evaluation_url: str, payload: dict, max_retries: int = 8):
    for attempt in range(max_retries):
        try:
            r = requests.post(evaluation_url, json=payload, timeout=30)
            if r.status_code == 200:
                return
        except Exception as e:
            logger.warning(f"Evaluation POST failed (attempt {attempt+1}): {e}")
        time.sleep(2 ** attempt)
    raise Exception(f"Failed to POST to evaluation URL after {max_retries} attempts")

# --- Round Handlers ---
def handle_round1(data: dict):
    task = data["task"]
    nonce = data["nonce"]
    repo_name = f"{task}-{nonce}".replace(" ", "-")
    logger.info(f"Starting Round 1: {repo_name}")

    create_github_repo(repo_name)
    attachment_files = process_attachments(data.get("attachments", []))
    ai_files = ask_aipipe_for_files(data["brief"], data.get("attachments"))
    all_files = {**ai_files, **attachment_files}

    commit_shas = {}
    latest_sha = None
    for path, content in all_files.items():
        if path not in ["README.md", "LICENSE"]:
            result = push_file_safe(repo_name, path, content, f"Add {path}")
            if not result.get("skipped"):
                sha = result.get("commit", {}).get("sha")
                commit_shas[path] = sha or "unknown"
                latest_sha = sha or latest_sha

    # Required files
    readme = generate_readme(repo_name, data["brief"], data["checks"])
    result = push_file_safe(repo_name, "README.md", readme.encode(), "Add README")
    sha = result.get("commit", {}).get("sha") if not result.get("skipped") else None
    if sha:
        latest_sha = sha

    license_content = generate_mit_license()
    result = push_file_safe(repo_name, "LICENSE", license_content.encode(), "Add LICENSE")
    sha = result.get("commit", {}).get("sha") if not result.get("skipped") else None
    if sha:
        latest_sha = sha

    enable_github_pages(repo_name)
    pages_url = f"https://{GITHUB_USER}.github.io/{repo_name}/"

    payload = {
        "email": data["email"],
        "task": task,
        "round": 1,
        "nonce": nonce,
        "repo_url": f"https://github.com/{GITHUB_USER}/{repo_name}",
        "commit_sha": latest_sha,
        "pages_url": pages_url
    }

    if data.get("evaluation_url"):
        post_to_evaluation_url(data["evaluation_url"], payload)

    logger.info(f"Round 1 completed: {pages_url}")
    return payload

def handle_round2(data: dict):
   
    task = data["task"]
    nonce = data["nonce"]
    repo_name = f"{task}-{nonce}".replace(" ", "-")
    brief = data["brief"]
    attachments = data.get("attachments", [])
    evaluation_url = data.get("evaluation_url")
    checks = data.get("checks", [])
    
    logger.info(f"Starting Round 2: {repo_name}")

    # Process attachments
    attachment_files = process_attachments(attachments)
    
    # Generate updated files via AI
    ai_files = ask_aipipe_for_files(brief, attachments)
    
    all_files = {**ai_files, **attachment_files}
    
    # Push files safely
    commit_shas = {}
    for path, content in all_files.items():
        if path not in ["README.md", "LICENSE"]:
            result = push_file_safe(repo_name, path, content, f"Round 2: Update {path}")
            if not result.get("skipped"):
                sha = result.get("commit", {}).get("sha")
                commit_shas[path] = sha or "unknown"

    # Update README.md according to new brief/features
    readme_content = generate_readme(repo_name, brief, checks)
    result = push_file_safe(repo_name, "README.md", readme_content.encode(), "Round 2: Update README")
    if not result.get("skipped"):
        sha = result.get("commit", {}).get("sha")
        commit_shas["README.md"] = sha or "unknown"

    # Ensure LICENSE exists (won't overwrite if present)
    license_content = generate_mit_license()
    push_file_safe(repo_name, "LICENSE", license_content.encode(), "Ensure LICENSE exists")

    # Redeploy GitHub Pages explicitly
    enable_github_pages(repo_name)
    pages_url = f"https://{GITHUB_USER}.github.io/{repo_name}/"

    # Prepare evaluation payload
    payload = {
        "email": data["email"],
        "task": task,
        "round": 2,
        "nonce": nonce,
        "repo_url": f"https://github.com/{GITHUB_USER}/{repo_name}",
        "commit_shas": commit_shas,
        "pages_url": pages_url
    }

    # POST to evaluation URL with retries
    if evaluation_url:
        try:
            post_to_evaluation_url(evaluation_url, payload)
        except Exception as e:
            logger.error(f"Failed to POST evaluation for Round 2: {e}")

    logger.info(f"Round 2 completed: {pages_url}")
    return payload


# --- API Endpoints ---
@app.post("/handle_task")
async def handle_task(request: Request):
    try:
        data = await request.json()
        if not validate_secret(data.get("secret", "")):
            return {"error": "Invalid secret"}

        required = ["email", "task", "round", "nonce", "brief", "checks", "evaluation_url"]
        for field in required:
            if field not in data:
                return {"error": f"Missing {field}"}

        if data["round"] == 1:
            return handle_round1(data)
        elif data["round"] == 2:
            return handle_round2(data)
        else:
            return {"error": f"Unsupported round {data['round']}"}
    except Exception as e:
        logger.error(f"Handler failed: {e}")
        return {"error": str(e)}

@app.get("/")
async def health_check():
    return {"status": "ready", "service": "LLM Code Deployment"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
